{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you should implement a first version of a working machine learning model to predict the age of an Abalone.\n",
    "\n",
    "A few guidelines:\n",
    "- The model does not have to be complex. A simple linear regression model is enough.\n",
    "- You should use MLflow to track your experiments. You can use the MLflow UI to compare your experiments.\n",
    "- Do not push any MLflow data to the repository. Only the code to run the experiments is interesting and should be pushed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing MLflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the tracking server URI, where the experiments and runs are going to be logged. We observe it refers to a local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"../mlruns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skrub import TableVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "# === Pipeline ===\n",
    "pipe = make_pipeline(\n",
    "    TableVectorizer(numeric=StandardScaler()),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# === Fonctions ===\n",
    "def evaluate_fold(X_train, y_train, X_test, y_test, pipeline):\n",
    "    \"\"\"Evaluate a single fold of cross-validation for the given pipeline.\"\"\"\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_train_pred)\n",
    "    rmse_test = root_mean_squared_error(y_test, y_test_pred)\n",
    "    return rmse_train, rmse_test\n",
    "\n",
    "\n",
    "def plot_coefficients_variability(coef_list: List[np.ndarray], feature_names: List[str]):\n",
    "    \"\"\"\n",
    "    Plot coefficient variability across folds as:\n",
    "    - a boxplot (dispersion des coefficients)\n",
    "    - une heatmap de corrélation entre coefficients\n",
    "    \"\"\"\n",
    "    coef_array = np.vstack(coef_list)  # (n_folds, n_features)\n",
    "\n",
    "    # ---- Boxplot ----\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax[0].boxplot(coef_array, vert=True, patch_artist=True,\n",
    "                  boxprops=dict(facecolor=\"#add8e6\", color=\"#007acc\"),\n",
    "                  medianprops=dict(color=\"red\"))\n",
    "    ax[0].set_title(\"Variabilité des coefficients (Boxplot)\")\n",
    "    ax[0].set_xlabel(\"Features\")\n",
    "    ax[0].set_ylabel(\"Coefficient Value\")\n",
    "    ax[0].set_xticks(range(1, len(feature_names) + 1))\n",
    "    ax[0].set_xticklabels(feature_names, rotation=45, ha=\"right\", fontsize=9)\n",
    "\n",
    "    # ---- Heatmap de corrélation ----\n",
    "    corr = np.corrcoef(coef_array)  # corrélation entre folds\n",
    "    sns.heatmap(corr, cmap=\"coolwarm\", center=0, annot=False, ax=ax[1])\n",
    "    ax[1].set_title(\"Corrélation entre les coefficients des folds\")\n",
    "    ax[1].set_xlabel(\"Fold index\")\n",
    "    ax[1].set_ylabel(\"Fold index\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def evaluate_cv(pipeline, X, y, n_splits=5, n_repeats=2, random_state=42, verbose=False):\n",
    "    \"\"\"Evaluate the pipeline using Repeated K-Fold cross-validation.\"\"\"\n",
    "    rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "    rmse_train_list, rmse_test_list, coef_list = [], [], []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(rkf.split(X), start=1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        rmse_train, rmse_test = evaluate_fold(X_train, y_train, X_test, y_test, pipeline)\n",
    "        rmse_train_list.append(rmse_train)\n",
    "        rmse_test_list.append(rmse_test)\n",
    "        # Extraire les coefficients du modèle LinearRegression\n",
    "        coef_list.append(pipeline.named_steps[\"linearregression\"].coef_.ravel())\n",
    "\n",
    "    # Extraire les noms de features du TableVectorizer\n",
    "    feature_names = pipeline.named_steps[\"tablevectorizer\"].get_feature_names_out()\n",
    "\n",
    "    results = {\n",
    "        \"rmse_train_mean\": np.mean(rmse_train_list),\n",
    "        \"rmse_train_std\": np.std(rmse_train_list),\n",
    "        \"rmse_test_mean\": np.mean(rmse_test_list),\n",
    "        \"rmse_test_std\": np.std(rmse_test_list),\n",
    "    }\n",
    "\n",
    "    fig = plot_coefficients_variability(coef_list, feature_names)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Train RMSE: {results['rmse_train_mean']:.4f} ± {results['rmse_train_std']:.4f}\")\n",
    "        print(f\"Test RMSE:  {results['rmse_test_mean']:.4f} ± {results['rmse_test_std']:.4f}\")\n",
    "\n",
    "    return results, fig\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the abalone dataset from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(\"../data/abalone.csv\")\n",
    "    X, y = df.drop(columns=[\"Rings\"]), df[[\"Rings\"]]\n",
    "    return X, y\n",
    "\n",
    "# === Exécution ===\n",
    "X, y = load_data()\n",
    "results, fig = evaluate_cv(pipe, X, y, verbose=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "# Set the experiment name\n",
    "mlflow_experiment_path = f\"/mlflow/linear_reg_abalone\"\n",
    "mlflow.set_experiment(mlflow_experiment_path)\n",
    "\n",
    "# ne sérialise pas automatiquement le modèle\n",
    "mlflow.sklearn.autolog(log_models=False, log_datasets=False)\n",
    "# Start a run\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    mlflow.set_tag(\"user\", \"Big_Bouzzz\")\n",
    "\n",
    "    X, y = load_data()\n",
    "    mlflow.log_param(\"n_samples\", X.shape[0])\n",
    "    mlflow.log_param(\"n_features\", X.shape[1])\n",
    "\n",
    "    result, fig = evaluate_cv(pipe, X, y, verbose=True)\n",
    "    for key, value in results.items():\n",
    "        mlflow.log_metric(key, value)\n",
    "\n",
    "    # Log the coefficient variability plot\n",
    "    mlflow.log_figure(fig, \"coefficient_variability.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle est clairement pas fou mais c'est pas le but ici ...\n",
    "\n",
    "On changera si on a le temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is satisfactory, we stage it as production using the appropriate version. This will help us retreiving it for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run() as run:\n",
    "    X, y = load_data()\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    # Log les performances\n",
    "    results, fig = evaluate_cv(pipe, X, y)\n",
    "    for key, value in results.items():\n",
    "        mlflow.log_metric(key, value)\n",
    "\n",
    "    # Log du modèle sous un nom stable\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipe,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"LinearRegression_Abalone\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "production_version = 1\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=\"LinearRegression_Abalone\", version=production_version, stage=\"Production\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhec-mlops-project-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
